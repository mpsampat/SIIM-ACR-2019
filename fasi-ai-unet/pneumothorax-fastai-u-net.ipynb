{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel guideline\n",
    "\n",
    "### Version 2 - start here\n",
    "* Image size 128x128\n",
    "* Unet with pretrained resnet34 encoder\n",
    "* Best threshold selection\n",
    "* Output visualization\n",
    "* Total run time of about 34 minutes\n",
    "\n",
    "### Version 3 - 5-fold ensemble\n",
    "* Example of 5-fold ensemble using sklearn KFold function, based on version 2\n",
    "* Changed learning rates\n",
    "* Total run time of about 132 minutes\n",
    "\n",
    "### Version 4 - 256x256 \n",
    "* Based on version 2 but with images of size 256x256\n",
    "* Batch size reduced to 32\n",
    "\n",
    "### Where to go next?\n",
    "* Look at as many examples as you can and try to understand why the model fails when it does;\n",
    "* There are several ways to convert a 1024x1024 to a lower resolution (e.g., bilinear, nearest), some may be more appropriate to this competition than others;\n",
    "* Progressive rescaling (start with small images like 64x64, train, save the weights, increase to 128x128, train with previous weights, and so on);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from mask_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.55'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 768\n",
    "path = Path(f'../data{SZ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# copy pretrained weights for resnet34 to the folder fastai will search by default\n",
    "Path('/tmp/.cache/torch/checkpoints/').mkdir(exist_ok=True, parents=True)\n",
    "#!cp '../input/resnet34/resnet34.pth' '/tmp/.cache/torch/checkpoints/resnet34-333f7ec4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Setting div=True in open_mask\n",
    "class SegmentationLabelList(SegmentationLabelList):\n",
    "    def open(self, fn): return open_mask(fn, div=True)\n",
    "    \n",
    "class SegmentationItemList(SegmentationItemList):\n",
    "    _label_cls = SegmentationLabelList\n",
    "\n",
    "# Setting transformations on masks to False on test set\n",
    "def transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n",
    "    if not tfms: tfms=(None,None)\n",
    "    assert is_listy(tfms) and len(tfms) == 2\n",
    "    self.train.transform(tfms[0], **kwargs)\n",
    "    self.valid.transform(tfms[1], **kwargs)\n",
    "    kwargs['tfm_y'] = False # Test data has no labels\n",
    "    if self.test: self.test.transform(tfms[1], **kwargs)\n",
    "    return self\n",
    "fastai.data_block.ItemLists.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create databunch\n",
    "data = (SegmentationItemList.from_folder(path=path/'train')\n",
    "        .split_by_rand_pct(0.2)\n",
    "        .label_from_func(lambda x : str(x).replace('train', 'masks'), classes=[0, 1])\n",
    "        .add_test((path/'test').ls(), label=None)\n",
    "        .transform(get_transforms(), size=SZ, tfm_y=True)\n",
    "        .databunch(path=Path('.'), bs=2)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some images with masks\n",
    "#data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create U-Net with a pretrained resnet34 as encoder\n",
    "learn = unet_learner(data, models.resnet34, metrics=[dice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.134149</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>31:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.762098</td>\n",
       "      <td>0.025959</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>31:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.026563</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>31:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025104</td>\n",
       "      <td>0.026672</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>31:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>31:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>0.025520</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>31:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit one cycle of 6 epochs with max lr of 1e-3\n",
    "learn.fit_one_cycle(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the encoder (resnet34)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='13' class='' max='18', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      72.22% [13/18 7:09:25<2:45:09]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.024763</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>32:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.025352</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.031696</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.682436</td>\n",
       "      <td>33:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.025362</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.013819</td>\n",
       "      <td>0.026794</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023053</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014488</td>\n",
       "      <td>0.025579</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>0.025299</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.020634</td>\n",
       "      <td>0.025062</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.024836</td>\n",
       "      <td>0.024313</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.018854</td>\n",
       "      <td>0.024116</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>33:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3809' class='' max='4270', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      89.20% [3809/4270 27:03<03:16 0.0250]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit one cycle of 12 epochs\n",
    "lr = 1e-3\n",
    "learn.fit_one_cycle(18, slice(lr/30, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the validation set\n",
    "preds, ys = learn.get_preds()\n",
    "preds = preds[:,1,...]\n",
    "ys = ys.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_overall(preds, targs):\n",
    "    n = preds.shape[0]\n",
    "    preds = preds.view(n, -1)\n",
    "    targs = targs.view(n, -1)\n",
    "    intersect = (preds * targs).sum(-1).float()\n",
    "    union = (preds+targs).sum(-1).float()\n",
    "    u0 = union==0\n",
    "    intersect[u0] = 1\n",
    "    union[u0] = 2\n",
    "    return (2. * intersect / union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold\n",
    "dices = []\n",
    "thrs = np.arange(0.01, 1, 0.01)\n",
    "for i in progress_bar(thrs):\n",
    "    preds_m = (preds>i).long()\n",
    "    dices.append(dice_overall(preds_m, ys).mean())\n",
    "dices = np.array(dices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dice = dices.max()\n",
    "best_thr = thrs[dices.argmax()]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(thrs, dices)\n",
    "plt.vlines(x=best_thr, ymin=dices.min(), ymax=dices.max())\n",
    "plt.text(best_thr+0.03, best_dice-0.01, f'DICE = {best_dice:.3f}', fontsize=14);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some samples\n",
    "rows = 10\n",
    "plot_idx = ys.sum((1,2)).sort(descending=True).indices[:rows]\n",
    "for idx in plot_idx:\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "    ax0.imshow(data.valid_ds[idx][0].data.numpy().transpose(1,2,0))\n",
    "    ax1.imshow(ys[idx], vmin=0, vmax=1)\n",
    "    ax2.imshow(preds[idx], vmin=0, vmax=1)\n",
    "    ax1.set_title('Targets')\n",
    "    ax2.set_title('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for test set\n",
    "preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n",
    "preds = (preds[:,1,...]>best_thr).long().numpy()\n",
    "print(preds.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rle encodings (images are first converted to the original size)\n",
    "rles = []\n",
    "for p in progress_bar(preds):\n",
    "    im = PIL.Image.fromarray((p.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "    im = np.asarray(im)\n",
    "    rles.append(mask2rle(im, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [o.stem for o in data.test_ds.items]\n",
    "sub_df = pd.DataFrame({'ImageId': ids, 'EncodedPixels': rles})\n",
    "sub_df.loc[sub_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
